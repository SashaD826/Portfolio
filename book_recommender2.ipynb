{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da1d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasha\\AppData\\Local\\Temp\\ipykernel_1348\\3807600768.py:23: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv('C:\\\\Users\\\\sasha\\\\Documents\\\\Data Analysis\\\\book_recommender\\\\BX-Books.csv',  encoding='cp1251', sep=';', on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: 'Stranger' was written by a different author or it doesn't have enough reviews. Also, Try to decrease fuzz threshold.\n",
      "\n",
      "Warning: 'Come A Stranger' was written by a different author or it doesn't have enough reviews. Also, Try to decrease fuzz threshold.\n",
      "\n",
      "Books that matched your input:\n",
      "                                          Book-Title\n",
      "0  Stranger In A Strange Land (Remembering Tomorrow)\n",
      "1                         Stranger In A Strange Land\n",
      "\n",
      "Top recommendations for 'Stranger In A Strange Land' by Heinlein:\n",
      "                                                                book  corr  avg_rating\n",
      "                                                         animal farm   1.0       9.667\n",
      "                                         tales of the cthulhu mythos   1.0       9.667\n",
      "                                                  the caves of steel   1.0       9.333\n",
      "the ritual bath (peter decker &amp; rina lazarus novels (paperback))   1.0       9.333\n",
      "   zen and the art of motorcycle maintenance: an inquiry into values   1.0       9.250\n",
      "                                                 the mists of avalon   1.0       9.200\n",
      "      anne of green gables (anne of green gables novels (paperback))   1.0       9.000\n",
      "                                         little house on the prairie   1.0       8.667\n",
      "                             midnight in the garden of good and evil   1.0       8.667\n",
      "                                                         rainbow six   1.0       8.667\n",
      "\n",
      "Bottom recommendations for 'Stranger In A Strange Land' by Heinlein:\n",
      "                                                    book   corr  avg_rating\n",
      "                                    name of the rose-nla -0.189       7.333\n",
      "                        patriot games (jack ryan novels) -0.189       8.333\n",
      "                        charlotte's web (trophy newbery) -0.174       8.750\n",
      "                                     the handmaid's tale -0.153       9.000\n",
      "                                       the pelican brief -0.115       6.667\n",
      "                                        bless me, ultima -0.115       6.667\n",
      "b is for burglar (kinsey millhone mysteries (paperback)) -0.115       7.250\n",
      "              children of dune (dune chronicles, book 3) -0.098       8.400\n",
      "                                    a widow for one year -0.052       7.750\n",
      "          the two towers (the lord of the rings, part 2) -0.039       9.364\n"
     ]
    }
   ],
   "source": [
    "# Parameters entered by user\n",
    "number_review_limit  = 3\n",
    "search_term = [\"stranger in a strange land\"]\n",
    "author = 'heinlein'\n",
    "# Fuzzywuzzy score: higher score = more strict comparison of the string\n",
    "threshold = 70\n",
    "\n",
    "# import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "                                        # IMPORT AND DATA CLEANING\n",
    "# Here will you have to download a zip file from my Github, there you will find 2 csv files, copy the first file path into the brackets below\n",
    "\n",
    "# load ratings\n",
    "ratings = pd.read_csv('', encoding='cp1251', sep=';', on_bad_lines='skip')\n",
    "ratings = ratings[ratings['Book-Rating']!=0]\n",
    "ratings = ratings.dropna(subset=['Book-Rating'])\n",
    "\n",
    "# Copy the second file path into the brackets below\n",
    "# load books\n",
    "books = pd.read_csv('',  encoding='cp1251', sep=';', on_bad_lines='skip')\n",
    "\n",
    "# Drop unnecessary columns to speed up the process\n",
    "books.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis = 1, inplace=True)\n",
    "\n",
    "                                        # MERGING AND DATA STANDARDIZATION\n",
    "\n",
    "#users_ratings = pd.merge(ratings, users, on='User-ID')\n",
    "dataset = pd.merge(ratings, books, on='ISBN')\n",
    "\n",
    "# Convert all object values in all columns to lowercase\n",
    "dataset_lowercase=dataset.apply(lambda x: x.str.lower() if(x.dtype == 'object') else x)\n",
    "\n",
    "# Strip whitespaces from all columns\n",
    "dataset_lowercase = dataset_lowercase.apply(lambda x: x.str.strip() if x.dtype in ['object', 'string'] else x)\n",
    "\n",
    "# Defining method how to search for similarities in a book title\n",
    "def find_similar_books(search_term, titles, threshold=threshold, scorer=fuzz.token_set_ratio):\n",
    "\n",
    "# Use process.extract to get scores for all titles\n",
    "    matches = process.extract(search_term, titles, scorer=scorer)\n",
    "    \n",
    "# Filter matches based on threshold\n",
    "    return [title for title, score in matches if score >= threshold]\n",
    "\n",
    "# Return unique book titles\n",
    "book_titles = dataset_lowercase['Book-Title'].unique()\n",
    "\n",
    "# A list of books that match\n",
    "matches = find_similar_books(search_term[0], book_titles, threshold=threshold)\n",
    "\n",
    "                                        # LIMITING DATASET TO SIMILAR USERS AND BOOKS THEY READ\n",
    "\n",
    "# Limit dataset to readers that read the book entered by the user\n",
    "similar_readers = dataset_lowercase['User-ID'][(dataset_lowercase['Book-Title'].isin(matches)) & \n",
    "        (dataset_lowercase['Book-Author'].str.contains(author))]\n",
    "\n",
    "# Table with books that matched the book title input by the user\n",
    "books_matched = dataset_lowercase[(dataset_lowercase['Book-Title'].isin(matches)) & \n",
    "        (dataset_lowercase['Book-Author'].str.contains(author))]['Book-Title'].unique()\n",
    "books_matched = pd.DataFrame(books_matched, columns = ['Book-Title'])\n",
    "\n",
    "# Convert into a list\n",
    "similar_readers = similar_readers.tolist()\n",
    "# Drop duplicates\n",
    "similar_readers = np.unique(similar_readers)\n",
    "\n",
    "# Books that got reviewed by the same readers that read the book chosen by the user\n",
    "books_of_similar_readers = dataset_lowercase[dataset_lowercase['User-ID'].isin(similar_readers)]\n",
    "\n",
    "# Number of ratings per other books in dataset\n",
    "number_of_rating_per_book = books_of_similar_readers.groupby('Book-Title').count().reset_index()\n",
    "\n",
    "#select only books which have actually higher number of ratings than threshold\n",
    "books_to_compare = number_of_rating_per_book['Book-Title'][number_of_rating_per_book['User-ID'] >= number_review_limit]\n",
    "books_to_compare2 = books_to_compare.tolist()\n",
    "\n",
    "# Table with books that matched the book title input by the user and have enough reviews\n",
    "books_matched2 = pd.merge(books_matched, books_to_compare, on = 'Book-Title', how = 'left')\n",
    "books_matched2 = books_matched2.apply(lambda x: x.str.title() if(x.dtype == 'object') else x)\n",
    "\n",
    "ratings_data_raw = books_of_similar_readers[['User-ID', 'Book-Rating', 'Book-Title']][\n",
    "    books_of_similar_readers['Book-Title'].isin(books_to_compare2)]\n",
    "\n",
    "# Group by User and Book and compute mean\n",
    "ratings_data_raw_nodup = ratings_data_raw.groupby(['User-ID', 'Book-Title'])['Book-Rating'].mean()\n",
    "\n",
    "# Reset index to see User-ID in every row\n",
    "ratings_data_raw_nodup = ratings_data_raw_nodup.to_frame().reset_index()\n",
    "\n",
    "dataset_for_corr = ratings_data_raw_nodup.pivot(index='User-ID', columns='Book-Title', values='Book-Rating')\n",
    "\n",
    "result_list = []\n",
    "worst_list = []\n",
    "\n",
    "                                        # FAIL-SAVES\n",
    "\n",
    "# Validate user input\n",
    "if not search_term or not author:\n",
    "    raise ValueError(\"Book title and author must be provided.\")\n",
    "if not isinstance(search_term, list):\n",
    "    search_term = [search_term]\n",
    "\n",
    "# Check if the book exists in the dataset\n",
    "book_exists = dataset_lowercase[\n",
    "    (dataset_lowercase['Book-Title'].isin(matches)) &\n",
    "    (dataset_lowercase['Book-Author'].str.contains(author, na=False))\n",
    "]\n",
    "if book_exists.empty:\n",
    "    raise ValueError(f\"No book matching '{search_term[0].title()}' by '{author.title()}' found in the dataset. Check for typos in the book title\")\n",
    "\n",
    "                                        # CORRELATIONS\n",
    "\n",
    "# Drop the book and its variation that was chosen by the user\n",
    "for match in matches:\n",
    "\n",
    "    # One more fail-safe\n",
    "    if match not in dataset_for_corr.columns:\n",
    "        print(f\"\\nWarning: '{match.title()}' was written by a different author or it doesn't have enough reviews. Also, Try to decrease fuzz threshold.\")\n",
    "        continue\n",
    "\n",
    "    #Take out user's favourite book from correlation dataframe\n",
    "    dataset_of_other_books = dataset_for_corr.copy(deep=False)\n",
    "    dataset_of_other_books.drop(match, axis=1, inplace=True)\n",
    "      \n",
    "    # empty lists\n",
    "    book_titles = []\n",
    "    correlations = []\n",
    "    avgrating = []          \n",
    "\n",
    "    # Calculate Pearson correlation coefficient for each book\n",
    "    for other_book in list(dataset_of_other_books.columns.values):\n",
    "        book_titles.append(other_book)\n",
    "        correlations.append(dataset_for_corr[match].corr(dataset_of_other_books[other_book]))\n",
    "        mean_rating = ratings_data_raw[ratings_data_raw['Book-Title']==other_book]['Book-Rating'].mean()\n",
    "        avgrating.append(mean_rating)\n",
    "        \n",
    "    # final dataframe of all correlation of each book   \n",
    "    corr_book_chosen = pd.DataFrame(list(zip(book_titles, np.round(correlations, 3), np.round(avgrating, 3))), columns=['book','corr','avg_rating'])\n",
    "    corr_book_chosen = corr_book_chosen[corr_book_chosen['corr'].notnull()]\n",
    "\n",
    "    # top 10 books with highest correlation\n",
    "    result_list.append(corr_book_chosen[corr_book_chosen['corr'] > 0].sort_values(['corr', 'avg_rating'], ascending = [False, False]).head(10))\n",
    "    \n",
    "    #10 books with the lowest correlation\n",
    "    worst_list.append(corr_book_chosen[corr_book_chosen['corr'] < 0].sort_values(['corr', 'avg_rating'], ascending = [False, False])[::-1].tail(10))\n",
    "  \n",
    "\n",
    "# Show results \n",
    "print(f\"\\nBooks that matched your input:\")\n",
    "print(books_matched2)\n",
    "if matches: \n",
    "    print(f\"\\nTop recommendations for '{search_term[0].title()}' by {author.title()}:\")\n",
    "    if len(result_list) > 0 and not result_list[0].empty:\n",
    "        print(result_list[0].to_string(index=False))\n",
    "    else:\n",
    "        print(f\"No top recommendations found for '{search_term[0].title()}' by {author.title()}. \"\n",
    "              f\"This may be due to insufficient ratings or correlations. Try decreasing the review limit.\")\n",
    "    print(f\"\\nBottom recommendations for '{search_term[0].title()}' by {author.title()}:\")\n",
    "    if len(worst_list) > 0 and not worst_list[0].empty:\n",
    "        print(worst_list[0].to_string(index=False))\n",
    "    else:\n",
    "        print(f\"No bottom recommendations found for '{search_term[0].title()}' by {author.title()}. \"\n",
    "              f\"This may be due to insufficient ratings or correlations. Try decreasing the review limit.\")\n",
    "else: \n",
    "    print(f\"\\nUnfortunately, our database doesn't have reviews of your favorite book\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
